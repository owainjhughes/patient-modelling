{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5573513-844b-4ef9-ba1c-5b5411841b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting Spark properly with a custom temp directory to avoid shuffle errors\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Set a safe local temp directory\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/temp/spark\"\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataAnalysis\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45362f19-0260-47a9-9006-1c7ed76ee3c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loading in the cleaned patient dataset\n",
    "df = spark.read.csv(\"cleaned_patients.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Quick look at first few rows\n",
    "df.show(5)\n",
    "\n",
    "# Checking what the structure of the data looks like\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fd6447-7d57-4cef-9370-7195a7137860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Picking out the main features to use in the model\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = [\"AGE\", \"OBESITY\", \"TOBACCO\", \"HIPERTENSION\", \"DIABETES\"]\n",
    "\n",
    "# Combining them into one feature column\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "df_transformed = assembler.transform(df)\n",
    "\n",
    "# Just checking that the features column looks alright\n",
    "df_transformed.select(\"AGE\", \"OBESITY\", \"TOBACCO\", \"HIPERTENSION\", \"DIABETES\", \"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c35c19-d288-4c88-ba3b-7f9227120bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using KMeans to group patients based on the features\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=3, seed=42, featuresCol=\"features\")\n",
    "kmeans_model = kmeans.fit(df_transformed)\n",
    "clusters = kmeans_model.transform(df_transformed)\n",
    "\n",
    "# Checking what cluster each patient ended up in\n",
    "clusters.select(\"features\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc6fef-fc80-4a88-83da-a42a1346e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing how ICU cases are spread across each cluster\n",
    "clusters.groupBy(\"prediction\", \"ICU\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8341f32-9e71-4c7c-b9ee-0dd291df7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Random Forest model to predict ICU\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"ICU\", featuresCol=\"features\", numTrees=100)\n",
    "rf_model = rf.fit(df_transformed)\n",
    "\n",
    "# Making predictions on full dataset\n",
    "rf_predictions = rf_model.transform(df_transformed)\n",
    "rf_predictions.select(\"features\", \"ICU\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d74f4-05b2-42bc-8462-f8c6c4361beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the dataset by oversampling ICU = 1 cases\n",
    "\n",
    "# Splitting the data into ICU = 1 (minority) and ICU = 2 (majority)\n",
    "minority = df_transformed.filter(df_transformed[\"ICU\"] == 1)\n",
    "majority = df_transformed.filter(df_transformed[\"ICU\"] == 2)\n",
    "\n",
    "# Duplicating the minority class to balance it\n",
    "oversampled = minority.sample(withReplacement=True, fraction=2.0)\n",
    "\n",
    "# Putting both groups back together\n",
    "balanced_data = majority.union(oversampled)\n",
    "\n",
    "# Shuffling the data\n",
    "from pyspark.sql.functions import rand\n",
    "balanced_data = balanced_data.orderBy(rand())\n",
    "\n",
    "# Checking how balanced it is now\n",
    "balanced_data.groupBy(\"ICU\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6d577-e671-4ec4-9d31-a5226446b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model again on the balanced dataset\n",
    "rf_balanced = RandomForestClassifier(labelCol=\"ICU\", featuresCol=\"features\", numTrees=100)\n",
    "rf_balanced_model = rf_balanced.fit(balanced_data)\n",
    "\n",
    "# Making new predictions\n",
    "balanced_predictions = rf_balanced_model.transform(balanced_data)\n",
    "balanced_predictions.select(\"features\", \"ICU\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753510b9-1f7e-46c4-90e2-14224694747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how accurate the model is\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(balanced_predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce812bad-aa13-4270-9dc0-7af63f4faf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra evaluation metrics\n",
    "f1_eval = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_eval.evaluate(balanced_predictions)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "precision_eval = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = precision_eval.evaluate(balanced_predictions)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "recall_eval = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = recall_eval.evaluate(balanced_predictions)\n",
    "print(f\"Recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931f8be8-391a-4429-a725-cfe95a51c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test sets\n",
    "train_data, test_data = balanced_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Just checking how many rows in each\n",
    "print(\"Train count:\", train_data.count())\n",
    "print(\"Test count:\", test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21730c3a-da6c-4a97-9dbc-c39295095775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training model on just the training data\n",
    "final_rf = RandomForestClassifier(labelCol=\"ICU\", featuresCol=\"features\", numTrees=100)\n",
    "final_model = final_rf.fit(train_data)\n",
    "\n",
    "# Predicting on test data\n",
    "test_preds = final_model.transform(test_data)\n",
    "test_preds.select(\"features\", \"ICU\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68087c66-d360-4d14-8b0a-95710a83cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test data\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\")\n",
    "\n",
    "acc = evaluator.setMetricName(\"accuracy\").evaluate(test_preds)\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(test_preds)\n",
    "prec = evaluator.setMetricName(\"weightedPrecision\").evaluate(test_preds)\n",
    "rec = evaluator.setMetricName(\"weightedRecall\").evaluate(test_preds)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall: {rec:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

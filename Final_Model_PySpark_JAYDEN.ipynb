{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5573513-844b-4ef9-ba1c-5b5411841b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-8JM7U52.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>BigDataAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1859f038190>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting Spark properly with a custom temp directory to avoid shuffle errors\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Set a safe local temp directory\n",
    "os.environ[\"SPARK_LOCAL_DIRS\"] = \"C:/temp/spark\"\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"BigDataAnalysis\").getOrCreate()\n",
    "spark\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45362f19-0260-47a9-9006-1c7ed76ee3c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+--------------------+----------+-------+---------+------------------+--------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+--------------------+---+\n",
      "|               USMER|        MEDICAL_UNIT|SEX|        PATIENT_TYPE| DATE_DIED|INTUBED|PNEUMONIA|               AGE|PREGNANT|DIABETES|COPD|ASTHMA|INMSUPR|HIPERTENSION|OTHER_DISEASE|CARDIOVASCULAR|OBESITY|RENAL_CHRONIC|TOBACCO|CLASIFFICATION_FINAL|ICU|\n",
      "+--------------------+--------------------+---+--------------------+----------+-------+---------+------------------+--------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+--------------------+---+\n",
      "| 0.03630966210657986| 0.01815483105328993|  2| 0.03630966210657986|09/06/2020|      1|        2|0.9985157079309461|       2|       1|   2|     2|      2|           2|            2|             2|      2|            2|      2|                   3|2.0|\n",
      "|0.049859965494422814|0.024929982747211407|  1|0.049859965494422814|9999-99-99|      2|        1|0.9971993098884563|       2|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                   3|2.0|\n",
      "| 0.05387724584403653|0.026938622922018266|  1| 0.05387724584403653|9999-99-99|      2|        2|0.9967290481146759|       2|       1|   2|     2|      2|           1|            2|             2|      1|            2|      2|                   3|2.0|\n",
      "| 0.07943014707895377| 0.03971507353947688|  1| 0.07943014707895377|9999-99-99|      2|        2| 0.992876838486922|       2|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                   3|2.0|\n",
      "| 0.08268982305947231|0.041344911529736156|  2| 0.08268982305947231|9999-99-99|      2|        2|0.9922778767136677|       2|       2|   2|     2|      2|           2|            2|             2|      2|            2|      2|                   3|2.0|\n",
      "+--------------------+--------------------+---+--------------------+----------+-------+---------+------------------+--------+--------+----+------+-------+------------+-------------+--------------+-------+-------------+-------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- USMER: double (nullable = true)\n",
      " |-- MEDICAL_UNIT: double (nullable = true)\n",
      " |-- SEX: integer (nullable = true)\n",
      " |-- PATIENT_TYPE: double (nullable = true)\n",
      " |-- DATE_DIED: string (nullable = true)\n",
      " |-- INTUBED: integer (nullable = true)\n",
      " |-- PNEUMONIA: integer (nullable = true)\n",
      " |-- AGE: double (nullable = true)\n",
      " |-- PREGNANT: integer (nullable = true)\n",
      " |-- DIABETES: integer (nullable = true)\n",
      " |-- COPD: integer (nullable = true)\n",
      " |-- ASTHMA: integer (nullable = true)\n",
      " |-- INMSUPR: integer (nullable = true)\n",
      " |-- HIPERTENSION: integer (nullable = true)\n",
      " |-- OTHER_DISEASE: integer (nullable = true)\n",
      " |-- CARDIOVASCULAR: integer (nullable = true)\n",
      " |-- OBESITY: integer (nullable = true)\n",
      " |-- RENAL_CHRONIC: integer (nullable = true)\n",
      " |-- TOBACCO: integer (nullable = true)\n",
      " |-- CLASIFFICATION_FINAL: integer (nullable = true)\n",
      " |-- ICU: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading in the cleaned patient dataset\n",
    "df = spark.read.csv(\"cleaned_patients.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Quick look at first few rows\n",
    "df.show(5)\n",
    "\n",
    "# Checking what the structure of the data looks like\n",
    "df.printSchema()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49fd6447-7d57-4cef-9370-7195a7137860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+-------+------------+--------+------------------------------------+\n",
      "|AGE               |OBESITY|TOBACCO|HIPERTENSION|DIABETES|features                            |\n",
      "+------------------+-------+-------+------------+--------+------------------------------------+\n",
      "|0.9985157079309461|2      |2      |2           |1       |[0.9985157079309461,2.0,2.0,2.0,1.0]|\n",
      "|0.9971993098884563|2      |2      |2           |2       |[0.9971993098884563,2.0,2.0,2.0,2.0]|\n",
      "|0.9967290481146759|1      |2      |1           |1       |[0.9967290481146759,1.0,2.0,1.0,1.0]|\n",
      "|0.992876838486922 |2      |2      |2           |2       |[0.992876838486922,2.0,2.0,2.0,2.0] |\n",
      "|0.9922778767136677|2      |2      |2           |2       |[0.9922778767136677,2.0,2.0,2.0,2.0]|\n",
      "+------------------+-------+-------+------------+--------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Picking out the main features to use in the model\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "features = [\"AGE\", \"OBESITY\", \"TOBACCO\", \"HIPERTENSION\", \"DIABETES\"]\n",
    "\n",
    "# Combining them into one feature column\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "df_transformed = assembler.transform(df)\n",
    "\n",
    "# Just checking that the features column looks alright\n",
    "df_transformed.select(\"AGE\", \"OBESITY\", \"TOBACCO\", \"HIPERTENSION\", \"DIABETES\", \"features\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c35c19-d288-4c88-ba3b-7f9227120bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|            features|prediction|\n",
      "+--------------------+----------+\n",
      "|[0.99851570793094...|         0|\n",
      "|[0.99719930988845...|         1|\n",
      "|[0.99672904811467...|         0|\n",
      "|[0.99287683848692...|         1|\n",
      "|[0.99227787671366...|         1|\n",
      "|[0.99503719020998...|         1|\n",
      "|[0.99929761570918...|         1|\n",
      "|[0.99870976937166...|         2|\n",
      "|[0.99778515785660...|         1|\n",
      "|[0.99778515785660...|         1|\n",
      "+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using KMeans to group patients based on the features\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=3, seed=42, featuresCol=\"features\")\n",
    "kmeans_model = kmeans.fit(df_transformed)\n",
    "clusters = kmeans_model.transform(df_transformed)\n",
    "\n",
    "# Checking what cluster each patient ended up in\n",
    "clusters.select(\"features\", \"prediction\").show(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32bc6fef-fc80-4a88-83da-a42a1346e5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+\n",
      "|prediction|ICU| count|\n",
      "+----------+---+------+\n",
      "|         2|1.0|  1119|\n",
      "|         0|2.0| 50602|\n",
      "|         1|2.0|115968|\n",
      "|         2|2.0| 12134|\n",
      "|         1|1.0|  9836|\n",
      "|         0|1.0|  4867|\n",
      "+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seeing how ICU cases are spread across each cluster\n",
    "clusters.groupBy(\"prediction\", \"ICU\").count().show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8341f32-9e71-4c7c-b9ee-0dd291df7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---+----------+-------------------------------------------+\n",
      "|features                            |ICU|prediction|probability                                |\n",
      "+------------------------------------+---+----------+-------------------------------------------+\n",
      "|[0.9985157079309461,2.0,2.0,2.0,1.0]|2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.9971993098884563,2.0,2.0,2.0,2.0]|2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.9967290481146759,1.0,2.0,1.0,1.0]|2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.992876838486922,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.9922778767136677,2.0,2.0,2.0,2.0]|2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.9950371902099892,2.0,2.0,2.0,2.0]|2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.9992976157091806,2.0,2.0,1.0,2.0]|1.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.9987097693716604,2.0,1.0,2.0,1.0]|1.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.997785157856609,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "|[0.997785157856609,2.0,2.0,2.0,2.0] |1.0|2.0       |[0.0,0.0813553519860528,0.9186446480139472]|\n",
      "+------------------------------------+---+----------+-------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a Random Forest model to predict ICU\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"ICU\", featuresCol=\"features\", numTrees=100)\n",
    "rf_model = rf.fit(df_transformed)\n",
    "\n",
    "# Making predictions on full dataset\n",
    "rf_predictions = rf_model.transform(df_transformed)\n",
    "rf_predictions.select(\"features\", \"ICU\", \"prediction\", \"probability\").show(10, truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4d74f4-05b2-42bc-8462-f8c6c4361beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|ICU| count|\n",
      "+---+------+\n",
      "|2.0|178704|\n",
      "|1.0| 31704|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Balancing the dataset by oversampling ICU = 1 cases\n",
    "\n",
    "# Splitting the data into ICU = 1 (minority) and ICU = 2 (majority)\n",
    "minority = df_transformed.filter(df_transformed[\"ICU\"] == 1)\n",
    "majority = df_transformed.filter(df_transformed[\"ICU\"] == 2)\n",
    "\n",
    "# Duplicating the minority class to balance it\n",
    "oversampled = minority.sample(withReplacement=True, fraction=2.0)\n",
    "\n",
    "# Putting both groups back together\n",
    "balanced_data = majority.union(oversampled)\n",
    "\n",
    "# Shuffling the data\n",
    "from pyspark.sql.functions import rand\n",
    "balanced_data = balanced_data.orderBy(rand())\n",
    "\n",
    "# Checking how balanced it is now\n",
    "balanced_data.groupBy(\"ICU\").count().show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0df6d577-e671-4ec4-9d31-a5226446b7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+---+----------+--------------------------------------------+\n",
      "|features                             |ICU|prediction|probability                                 |\n",
      "+-------------------------------------+---+----------+--------------------------------------------+\n",
      "|[0.9919952972186272,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.15358922631119284,0.8464107736888071]|\n",
      "|[0.8968700041677191,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.15308600753101764,0.8469139924689822]|\n",
      "|[0.9672747798780993,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.15358922631119284,0.8464107736888071]|\n",
      "|[0.9977369441329896,2.0,2.0,1.0,1.0] |2.0|2.0       |[0.0,0.14481709895494896,0.8551829010450511]|\n",
      "|[0.9937523518859899,2.0,2.0,1.0,2.0] |1.0|2.0       |[0.0,0.1438383777693017,0.8561616222306984] |\n",
      "|[0.9665486721013271,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.15358922631119284,0.8464107736888071]|\n",
      "|[0.9938586931957764,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.1438383777693017,0.8561616222306984] |\n",
      "|[0.9967838189153033,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.1438383777693017,0.8561616222306984] |\n",
      "|[0.9052038109696288,2.0,2.0,2.0,2.0] |2.0|2.0       |[0.0,0.15308600753101764,0.8469139924689822]|\n",
      "|[0.16169041669088866,2.0,2.0,2.0,2.0]|2.0|2.0       |[0.0,0.15308600753101764,0.8469139924689822]|\n",
      "+-------------------------------------+---+----------+--------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training the model again on the balanced dataset\n",
    "rf_balanced = RandomForestClassifier(labelCol=\"ICU\", featuresCol=\"features\", numTrees=100)\n",
    "rf_balanced_model = rf_balanced.fit(balanced_data)\n",
    "\n",
    "# Making new predictions\n",
    "balanced_predictions = rf_balanced_model.transform(balanced_data)\n",
    "balanced_predictions.select(\"features\", \"ICU\", \"prediction\", \"probability\").show(10, truncate=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753510b9-1f7e-46c4-90e2-14224694747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Checking how accurate the model is\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(balanced_predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce812bad-aa13-4270-9dc0-7af63f4faf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.78\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Extra evaluation metrics\n",
    "f1_eval = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1 = f1_eval.evaluate(balanced_predictions)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "precision_eval = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = precision_eval.evaluate(balanced_predictions)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "recall_eval = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = recall_eval.evaluate(balanced_predictions)\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "931f8be8-391a-4429-a725-cfe95a51c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train count: 168533\n",
      "Test count: 41866\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data into train and test sets\n",
    "train_data, test_data = balanced_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Just checking how many rows in each\n",
    "print(\"Train count:\", train_data.count())\n",
    "print(\"Test count:\", test_data.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21730c3a-da6c-4a97-9dbc-c39295095775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+---+----------+--------------------------------------------+\n",
      "|features                            |ICU|prediction|probability                                 |\n",
      "+------------------------------------+---+----------+--------------------------------------------+\n",
      "|[0.9926322333149494,2.0,2.0,1.0,2.0]|2.0|2.0       |[0.0,0.1520862287528701,0.84791377124713]   |\n",
      "|[0.9979562822891704,2.0,2.0,2.0,2.0]|2.0|2.0       |[0.0,0.14858448816733236,0.8514155118326676]|\n",
      "|[0.9989516508612453,2.0,2.0,2.0,2.0]|2.0|2.0       |[0.0,0.14858448816733236,0.8514155118326676]|\n",
      "|[0.9989303992660782,2.0,2.0,1.0,2.0]|2.0|2.0       |[0.0,0.14864682652016545,0.8513531734798346]|\n",
      "|[0.9921748659570819,2.0,2.0,2.0,2.0]|1.0|2.0       |[0.0,0.15129002721485163,0.8487099727851484]|\n",
      "|[0.9921748659570819,2.0,2.0,2.0,2.0]|1.0|2.0       |[0.0,0.15129002721485163,0.8487099727851484]|\n",
      "|[0.9977830021123382,1.0,2.0,2.0,2.0]|1.0|2.0       |[0.0,0.14909585914248147,0.8509041408575185]|\n",
      "|[0.9977362420237599,2.0,2.0,1.0,2.0]|2.0|2.0       |[0.0,0.14864682652016545,0.8513531734798346]|\n",
      "|[0.9916737395874833,2.0,2.0,1.0,2.0]|2.0|2.0       |[0.0,0.1520862287528701,0.84791377124713]   |\n",
      "|[0.9916737395874833,2.0,2.0,1.0,2.0]|2.0|2.0       |[0.0,0.1520862287528701,0.84791377124713]   |\n",
      "+------------------------------------+---+----------+--------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training model on just the training data\n",
    "final_rf = RandomForestClassifier(labelCol=\"ICU\", featuresCol=\"features\", numTrees=100)\n",
    "final_model = final_rf.fit(train_data)\n",
    "\n",
    "# Predicting on test data\n",
    "test_preds = final_model.transform(test_data)\n",
    "test_preds.select(\"features\", \"ICU\", \"prediction\", \"probability\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68087c66-d360-4d14-8b0a-95710a83cc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "F1 Score: 0.78\n",
      "Precision: 0.72\n",
      "Recall: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test data\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"ICU\", predictionCol=\"prediction\")\n",
    "\n",
    "acc = evaluator.setMetricName(\"accuracy\").evaluate(test_preds)\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(test_preds)\n",
    "prec = evaluator.setMetricName(\"weightedPrecision\").evaluate(test_preds)\n",
    "rec = evaluator.setMetricName(\"weightedRecall\").evaluate(test_preds)\n",
    "\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(f\"Precision: {prec:.2f}\")\n",
    "print(f\"Recall: {rec:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2224e0-7417-4530-b15b-d6d7c5347811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df312b-1e21-427d-bdda-000ee0e5285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeacbf8-baf6-441c-b82a-58a59973d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the raw patient dataset\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Viewing the top few rows to understand structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22873710-f48d-49d9-99c0-453fc821e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing '?' with NaN so we can handle missing values properly\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Converting all numeric columns to proper float type\n",
    "df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "# Filling missing numeric values with column means\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "# Filling missing categorical values with the most frequent value\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "# Checking for any remaining missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6bca3-35ff-4833-996f-e4e11f2a1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting clinical features and target variable\n",
    "features = ['AGE', 'OBESITY', 'TOBACCO', 'HIPERTENSION', 'DIABETES']\n",
    "X = df[features]\n",
    "y = df['ICU']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bd19c-3295-4123-82bb-fc258f396fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the features to improve model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49900e2-8290-4903-8111-1f6216322e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a basic Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe488c03-12cd-410e-b49d-13fc2c553f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions and showing evaluation metrics\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b2660-b83e-4c8f-84de-4b30125fa046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the Confusion Matrix for the Basic Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Getting confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotting heatmap for better visual interpretation\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[1, 2], yticklabels=[1, 2])\n",
    "plt.title(\"Confusion Matrix (Basic Model)\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b6dd1-a26d-4fd8-b917-0ff5027f6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a readable table for the Classification Report\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Getting classification report as a dictionary\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Converting to a clean pandas DataFrame\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Rounding numbers for clarity\n",
    "report_df = report_df.round(2)\n",
    "\n",
    "# Displaying the final table\n",
    "print(\"Classification Report (Detailed Table):\")\n",
    "print(report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cb480-a1bc-4dad-8005-114e1ee8bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the baseline logistic regression model\n",
    "# Using ICU as the target and main clinical features as input\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66d78f-6f9a-4a3c-95e5-c71e156de135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ROC Curve to understand the classifier performance visually\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Getting the predicted probabilities for ICU=2 (positive class)\n",
    "y_probs = log_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculating False Positive Rate, True Positive Rate and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_probs, pos_label=2.0)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotting the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\", linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guess\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve – Basic Logistic Regression Model\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cfdeb2-8a17-48f5-9cad-5edfa7d1f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the AUC score from the ROC Curve for better interpretability\n",
    "print(f\"AUC Score (Logistic Regression): {roc_auc:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cf6520-7553-45de-9d82-c1a1699db5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix as a heatmap for visual clarity\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generating predictions using the logistic regression model\n",
    "y_pred_basic = log_model.predict(X_test)\n",
    "\n",
    "# Creating confusion matrix\n",
    "cm_basic = confusion_matrix(y_test, y_pred_basic)\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm_basic, annot=True, fmt='d', cmap='Blues', xticklabels=[1.0, 2.0], yticklabels=[1.0, 2.0])\n",
    "plt.title(\"Confusion Matrix – Logistic Regression\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb1dbd1-9bd4-48a4-ae59-fd29be02b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importance using the logistic regression coefficients\n",
    "\n",
    "# Getting the feature names and their corresponding coefficients\n",
    "feature_names = X.columns\n",
    "coefs = pd.Series(log_model.coef_[0], index=feature_names).sort_values()\n",
    "\n",
    "# Creating the bar plot to visualise the importance\n",
    "plt.figure(figsize=(8, 6))\n",
    "coefs.plot(kind='barh', color='steelblue')\n",
    "plt.title(\"Feature Importance – Logistic Regression Coefficients\")\n",
    "plt.xlabel(\"Coefficient Weight\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96700191-82b6-4ac5-bf4f-8df462fe0e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing 5-Fold Cross Validation on the Logistic Regression model\n",
    "# Helps to check how stable the model is across different data splits\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Getting cross-validation scores based on accuracy\n",
    "cv_scores = cross_val_score(log_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Printing all the scores from the 5 folds\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "\n",
    "# Showing the average accuracy and how much it varies\n",
    "print(f\"Mean Accuracy: {cv_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation: {cv_scores.std():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7051bc-7655-442b-930b-262f1ad907a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained logistic regression model to a file\n",
    "# Good practice to save the model in case we need to load it again later\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Exporting model using joblib\n",
    "joblib.dump(log_model, 'basic_model_logistic_regression.pkl')\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Model saved successfully as 'basic_model_logistic_regression.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a8b53-dd16-4065-90dd-8d01067e663b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
